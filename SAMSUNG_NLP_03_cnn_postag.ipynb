{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SAMSUNG_NLP_03_cnn_postag.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNXlrQNh/+xA+TJIKeioHVU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Сверточные нейросети и POS-теггинг\n","\n","POS-теггинг - определение частей речи (снятие частеречной неоднозначности)"],"metadata":{"id":"oBX1yiorp1K4"}},{"cell_type":"code","source":["!pip install pyconll"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E-dmZOg5qTnY","executionInfo":{"status":"ok","timestamp":1644365457796,"user_tz":-300,"elapsed":3888,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"6635ff07-2f66-4454-e1a4-eeeda96df057"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyconll in /usr/local/lib/python3.7/dist-packages (3.1.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U7u0sIripcJG"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from sklearn.metrics import classification_report\n","\n","import numpy as np\n","\n","import pyconll\n","\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.utils.data import TensorDataset"]},{"cell_type":"code","source":["import random\n","\n","import numpy as np\n","import torch\n","\n","def init_random_seed(value=0):\n","  random.seed(value)\n","  np.random.seed(value)\n","  torch.manual_seed(value)\n","  torch.cuda.manual_seed(value)\n","  torch.backends.cudnn.deterministic = True"],"metadata":{"id":"tO2dmz1FrUBd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["init_random_seed()"],"metadata":{"id":"NwWRSAVrrcxs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Загрузка текстов и разбиение на обучающую и тестовую подвыборки"],"metadata":{"id":"xXhxnS6isfMY"}},{"cell_type":"code","source":["!wget -O ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/dan-zeman/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train.conllu\n","!wget -O ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/dan-zeman/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U84fWef7rgic","executionInfo":{"status":"ok","timestamp":1644365473161,"user_tz":-300,"elapsed":1282,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"7099fe64-447f-4955-d8f2-d2d73fabf5f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-02-09 00:11:15--  https://raw.githubusercontent.com/dan-zeman/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train.conllu\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 81043533 (77M) [text/plain]\n","Saving to: ‘ru_syntagrus-ud-train.conllu’\n","\n","ru_syntagrus-ud-tra 100%[===================>]  77.29M   208MB/s    in 0.4s    \n","\n","2022-02-09 00:11:15 (208 MB/s) - ‘ru_syntagrus-ud-train.conllu’ saved [81043533/81043533]\n","\n","--2022-02-09 00:11:16--  https://raw.githubusercontent.com/dan-zeman/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10903424 (10M) [text/plain]\n","Saving to: ‘ru_syntagrus-ud-dev.conllu’\n","\n","ru_syntagrus-ud-dev 100%[===================>]  10.40M  --.-KB/s    in 0.1s    \n","\n","2022-02-09 00:11:16 (95.7 MB/s) - ‘ru_syntagrus-ud-dev.conllu’ saved [10903424/10903424]\n","\n"]}]},{"cell_type":"code","source":["full_train = pyconll.load_from_file('ru_syntagrus-ud-train.conllu')\n","full_test = pyconll.load_from_file('ru_syntagrus-ud-dev.conllu')"],"metadata":{"id":"WaHm2u3yuP7U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for sent in full_train[:2]:\n","  for token in sent:\n","    print(token.form, token.upos)\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uF50kYVHunUu","executionInfo":{"status":"ok","timestamp":1644365501238,"user_tz":-300,"elapsed":246,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"07ff863c-073b-4a48-80d8-9f65cb00a237"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Анкета NOUN\n",". PUNCT\n","\n","Начальник NOUN\n","областного ADJ\n","управления NOUN\n","связи NOUN\n","Семен PROPN\n","Еремеевич PROPN\n","был AUX\n","человек NOUN\n","простой ADJ\n",", PUNCT\n","приходил VERB\n","на ADP\n","работу NOUN\n","всегда ADV\n","вовремя ADV\n",", PUNCT\n","здоровался VERB\n","с ADP\n","секретаршей NOUN\n","за ADP\n","руку NOUN\n","и CCONJ\n","иногда ADV\n","даже PART\n","писал VERB\n","в ADP\n","стенгазету NOUN\n","заметки NOUN\n","под ADP\n","псевдонимом NOUN\n","\" PUNCT\n","Муха NOUN\n","\" PUNCT\n",". PUNCT\n","\n"]}]},{"cell_type":"code","source":["MAX_SENT_LEN = max(len(sent) for sent in full_train)\n","MAX_ORIG_TOKEN_LEN = max(len(token.form) for sent in full_train for token in sent)\n","print('Наибольшая длина предложения', MAX_SENT_LEN)\n","print('Наибольшая длина токена', MAX_ORIG_TOKEN_LEN)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0KqU5JMbvE-8","executionInfo":{"status":"ok","timestamp":1644365503406,"user_tz":-300,"elapsed":600,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"d85b76d2-1b4b-4740-d400-0c5dea4e121c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Наибольшая длина предложения 205\n","Наибольшая длина токена 47\n"]}]},{"cell_type":"code","source":["all_train_texts = [' '.join(token.form for token in sent) for sent in full_train]\n","print('\\n'.join(all_train_texts[:10]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qOGgwFHux63V","executionInfo":{"status":"ok","timestamp":1644365506030,"user_tz":-300,"elapsed":692,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"958b54b3-da74-4200-8d89-78f09d01e963"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Анкета .\n","Начальник областного управления связи Семен Еремеевич был человек простой , приходил на работу всегда вовремя , здоровался с секретаршей за руку и иногда даже писал в стенгазету заметки под псевдонимом \" Муха \" .\n","В приемной его с утра ожидали посетители , - кое-кто с важными делами , а кое-кто и с такими , которые легко можно было решить в нижестоящих инстанциях , не затрудняя Семена Еремеевича .\n","Однако стиль работы Семена Еремеевича заключался в том , чтобы принимать всех желающих и лично вникать в дело .\n","Приемная была обставлена просто , но по-деловому .\n","У двери стоял стол секретарши , на столе - пишущая машинка с широкой кареткой .\n","В углу висел репродуктор и играло радио для развлечения ожидающих и еще для того , чтобы заглушать голос начальника , доносившийся из кабинета , так как , бесспорно , среди посетителей могли находиться и случайные люди .\n","Кабинет отличался скромностью , присущей Семену Еремеевичу .\n","В глубине стоял широкий письменный стол с бронзовыми чернильницами и перед ним два кожаных кресла .\n","Справа был стол для заседаний - длинный , накрытый зеленым сукном и с обеих сторон аккуратно заставленный стульями .\n"]}]},{"cell_type":"code","source":["import re\n","\n","TOKEN_RE = re.compile(r'[\\w\\d]+')\n","\n","def tokenize_text_simple_regex(txt, min_token_size=4):\n","  txt = txt.lower()\n","  all_tokens = TOKEN_RE.findall(txt)\n","  return [token for token in all_tokens if len(token) >= min_token_size]\n","\n","def tokenize_corpus(texts, tokenizer=tokenize_text_simple_regex, **tokenizer_kwargs):\n","  return [tokenizer(text, **tokenizer_kwargs) for text in texts]"],"metadata":{"id":"YsvaeYuKygS7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import collections\n","\n","import numpy as np\n","\n","def build_vocabulary(tokenized_texts, max_size=1000000, max_doc_freq=0.8, min_count=5, pad_word=None):\n","  word_counts = collections.defaultdict(int)\n","  doc_n = 0\n","\n","  # посчитать количество документов, в которых употребляется каждое слово,\n","  # а также общее количество документов\n","  for txt in tokenized_texts:\n","    doc_n += 1\n","    unique_text_tokens = set(txt)\n","    for token in unique_text_tokens:\n","      word_counts[token] += 1\n","\n","  # убрать слишком редкие и слишком частые слова\n","  word_counts = {word: cnt for word, cnt in word_counts.items() if cnt >= min_count and cnt / doc_n <= max_doc_freq}\n","\n","  # отсортировать слова по убыванию частоты\n","  sorted_word_counts = sorted(word_counts.items(),\n","                              reverse=True,\n","                              key=lambda pair: pair[1])\n","\n","  # добавим несуществующее слово с индексом 0 для удобства пакетной обработки\n","  if pad_word is not None:\n","    sorted_word_counts = [(pad_word, 0)] + sorted_word_counts\n","\n","  # если у нас по-прежнему слишком много слов, оставить только max_size самых частотных\n","  if len(word_counts) > max_size:\n","    sorted_word_counts = sorted_word_counts[:max_size]\n","\n","  # нумеруем слова\n","  word2id = {word: i for i, (word, _) in enumerate(sorted_word_counts)}\n","\n","  # нормируем частоты слов\n","  word2freq = np.array([cnt / doc_n for _, cnt in sorted_word_counts], dtype='float32')\n","\n","  return word2id, word2freq"],"metadata":{"id":"n_MO0pnAyqni"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def character_tokenize(txt):\n","  return list(txt)"],"metadata":{"id":"vt_2SbIDzQuf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_char_tokenized = tokenize_corpus(all_train_texts, tokenizer=character_tokenize)\n","char_vocab, word_doc_freq = build_vocabulary(train_char_tokenized, max_doc_freq=1.0, min_count=5, pad_word='<PAD>')\n","print('Количество уникальных символов', len(char_vocab))\n","print(list(char_vocab.items())[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lhcq4IW7yuuA","executionInfo":{"status":"ok","timestamp":1644365511736,"user_tz":-300,"elapsed":1001,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"71a96512-3735-4111-a8c3-947f8d92a9d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Количество уникальных символов 150\n","[('<PAD>', 0), (' ', 1), ('о', 2), ('е', 3), ('а', 4), ('т', 5), ('и', 6), ('н', 7), ('.', 8), ('с', 9)]\n"]}]},{"cell_type":"code","source":["UNIQUE_TAGS = ['<NOTAG>'] + sorted({token.upos for sent in full_train for token in sent if token.upos})\n","label2id = {label: i for i, label in enumerate(UNIQUE_TAGS)}\n","label2id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YJDxl_aI0S6V","executionInfo":{"status":"ok","timestamp":1644365513293,"user_tz":-300,"elapsed":589,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"bda49962-e77e-4417-8be6-a4c16159bb27"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'<NOTAG>': 0,\n"," 'ADJ': 1,\n"," 'ADP': 2,\n"," 'ADV': 3,\n"," 'AUX': 4,\n"," 'CCONJ': 5,\n"," 'DET': 6,\n"," 'INTJ': 7,\n"," 'NOUN': 8,\n"," 'NUM': 9,\n"," 'PART': 10,\n"," 'PRON': 11,\n"," 'PROPN': 12,\n"," 'PUNCT': 13,\n"," 'SCONJ': 14,\n"," 'SYM': 15,\n"," 'VERB': 16,\n"," 'X': 17}"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["import torch\n","\n","def pos_corpus_to_tensor(sentences, char2id, label2id, max_sent_len, max_token_len):\n","  inputs = torch.zeros((len(sentences), max_sent_len, max_token_len + 2), dtype=torch.long)\n","  targets = torch.zeros((len(sentences), max_sent_len), dtype=torch.long)\n","\n","  for sent_i, sent in enumerate(sentences):\n","    for token_i, token in enumerate(sent):\n","      targets[sent_i, token_i] = label2id.get(token.upos, 0)\n","      for char_i, char in enumerate(token.form):\n","        inputs[sent_i, token_i, char_i + 1] = char2id.get(char, 0)\n","\n","  return inputs, targets"],"metadata":{"id":"D9bN8whF016P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_inputs, train_labels = pos_corpus_to_tensor(full_train, char_vocab, label2id, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)\n","train_dataset = TensorDataset(train_inputs, train_labels)\n","\n","test_inputs, test_labels = pos_corpus_to_tensor(full_test, char_vocab, label2id, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)\n","test_dataset = TensorDataset(test_inputs, test_labels)"],"metadata":{"id":"7or20JEi3Apo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_inputs[1][:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2AbwSgC80deX","executionInfo":{"status":"ok","timestamp":1644365549097,"user_tz":-300,"elapsed":235,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"3c2c5f06-a174-426d-9231-7c30e0ddc983"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0, 39,  4, 25,  4, 11, 20,  7,  6, 13,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [ 0,  2, 23, 11,  4,  9,  5,  7,  2, 22,  2,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [ 0, 17, 16, 10,  4, 12, 11,  3,  7,  6, 19,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [ 0,  9, 12, 19, 21,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [ 0, 40,  3, 15,  3,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["train_labels[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mp5xGmpu7z9s","executionInfo":{"status":"ok","timestamp":1644365550308,"user_tz":-300,"elapsed":232,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"14a9306e-9908-4803-eecf-17a848bba44b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 8,  1,  8,  8, 12, 12,  4,  8,  1, 13, 16,  2,  8,  3,  3, 13, 16,  2,\n","         8,  2,  8,  5,  3, 10, 16,  2,  8,  8,  2,  8, 13,  8, 13, 13,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0])"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["##Вспомогательная сверточная архитектура"],"metadata":{"id":"UOcmqSEL75Z-"}},{"cell_type":"code","source":["class StackedConv1d(nn.Module):\n","  def __init__(self, features_num, layers_n=1, kernel_size=3, conv_layer=nn.Conv1d, dropout=0.0):\n","    super().__init__()\n","    layers = []\n","    for _ in range(layers_n):\n","      layers.append(nn.Sequential(\n","          conv_layer(features_num, features_num, kernel_size, padding=kernel_size//2),\n","          nn.Dropout(dropout),\n","          nn.LeakyReLU()))\n","    self.layers = nn.ModuleList(layers)\n","\n","  def forward(self, x):\n","    \"\"\"x - BatchSize x FeaturesNum x SequenceLen\"\"\"\n","    for layer in self.layers:\n","      x = x + layer(x)\n","    return x"],"metadata":{"id":"ffqvNP2D73Gs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Предсказание частей речи на уровне отдельных токенов"],"metadata":{"id":"jbkgTdsY_kqk"}},{"cell_type":"code","source":["class SingleTokenPOSTagger(nn.Module):\n","  def __init__(self, vocab_size, labels_num, embedding_size=32, **kwargs):\n","    super().__init__()\n","    self.char_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n","    self.backbone = StackedConv1d(embedding_size, **kwargs)\n","    self.global_pooling = nn.AdaptiveMaxPool1d(1)\n","    self.out = nn.Linear(embedding_size, labels_num)\n","    self.labels_num = labels_num\n","\n","  def forward(self, tokens):\n","    \"\"\"tokens - BatchSize x MaxSentencelen x MinTokenLen\"\"\"\n","    batch_size, max_sent_len, max_token_len = tokens.shape\n","    tokens_flat = tokens.view(batch_size * max_sent_len, max_token_len)\n","\n","    char_embeddings = self.char_embeddings(tokens_flat)  # BatchSize*MaxSentenceLen x MaxTokenLen x EmbSize\n","    char_embeddings = char_embeddings.permute(0, 2, 1)  # BatchSize*MaxSentenceLen x EmbSize x MaxTokenLen\n","\n","    features = self.backbone(char_embeddings)\n","\n","    global_features = self.global_pooling(features).squeeze(-1)  # BatchSize*MaxSentenceLen x EmbSize\n","\n","    logits_flat = self.out(global_features)  # BatchSize*MaxSentenceLen x LabelsNum\n","    logits = logits_flat.view(batch_size, max_sent_len, self.labels_num)  # BatchSize x MaxSentenceLen x LabelsNum\n","    logits = logits.permute(0, 2, 1)  # BatchSize x LabelsNum x MaxSentenceLen\n","    return logits"],"metadata":{"id":"K5_g8ONx95DK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["single_token_model = SingleTokenPOSTagger(len(char_vocab), len(label2id), embedding_size=64, layers_n=3, kernel_size=3, dropout=0.3)\n","print('Количество параметров', sum(np.product(t.shape) for t in single_token_model.parameters()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ngcsikb7DGJB","executionInfo":{"status":"ok","timestamp":1644365558155,"user_tz":-300,"elapsed":234,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"a20aaeb0-b702-46b9-a2a0-117c19a94a17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Количество параметров 47826\n"]}]},{"cell_type":"code","source":["import torch\n","\n","def copy_data_to_device(data, device):\n","  if torch.is_tensor(data):\n","    return data.to(device)\n","  elif isinstance(data, (list, tuple)):\n","    return [copy_data_to_device(elem, device) for elem in data]\n","  raise ValueError('Недопустимый тип данных {}'.format(type(data)))"],"metadata":{"id":"6vST5nfvEfRv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import copy\n","import datetime\n","import traceback\n","\n","import torch\n","from torch.utils.data import DataLoader\n","\n","def train_eval_loop(model, train_dataset, val_dataset, criterion,\n","                    lr=1e-4, epoch_n=10, batch_size=32,\n","                    device=None, early_stopping_patience=10, l2_reg_alpha=0,\n","                    max_batches_per_epoch_train=10000,\n","                    max_batches_per_epoch_val=1000,\n","                    data_loader_ctor=DataLoader,\n","                    optimizer_ctor=None,\n","                    lr_scheduler_ctor=None,\n","                    shuffle_train=True,\n","                    dataloader_workers_n=0):\n","  \"\"\"\n","  Цикл для обучения модели. После каждой эпохи качество модели оценивается по отложенной выборке.\n","  :param model: torch.nn.Module - обучаемая модель\n","  :param train_dataset: torch.utils.data.Dataset - данные для обучения\n","  :param val_dataset: torch.utils.data.Dataset - данные для оценки качества\n","  :param criterion: функция потерь для настройки модели\n","  :param lr: скорость обучения\n","  :param epoch_n: максимальное количество эпох\n","  :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n","  :param device: cuda/cpu - устройство, на котором выполнять вычисления\n","  :param early_stopping_patience: наибольшее количество эпох, в течение которых допускается\n","    отсутствие улучшения модели, чтобы обучение продолжалось.\n","  :param l2_reg_alpha: коэффициент L2-регуляризации\n","  :param max_batches_per_epoch_train: максимальное количество итераций на одну эпоху обучения\n","  :param max_batches_per_epoch_val: максимальное количество итераций на одну эпоху валидации\n","  :param data_loader_ctor: функция для создания объекта, преобразующего датасет в батчи\n","    (по умолчанию torch.utils.data.DataLoader)\n","  :return: кортеж из двух элементов:\n","    - среднее значение функции потерь на валидации на лучшей эпохе\n","    - лучшая модель\n","  \"\"\"\n","  if device is None:\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","  device = torch.device(device)\n","  model.to(device)\n","\n","  if optimizer_ctor is None:\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\n","  else:\n","    optimizer = optimizer_ctor(model.parameters(), lr=lr)\n","\n","  if lr_scheduler_ctor is not None:\n","    lr_scheduler = lr_scheduler_ctor(optimizer)\n","  else:\n","    lr_scheduler = None\n","\n","  train_dataloader = data_loader_ctor(train_dataset, batch_size=batch_size, shuffle=shuffle_train,\n","                                      num_workers=dataloader_workers_n)\n","  val_dataloader = data_loader_ctor(val_dataset, batch_size=batch_size, shuffle=False,\n","                                    num_workers=dataloader_workers_n)\n","  \n","  best_val_loss = float('inf')\n","  best_epoch_i = 0\n","  best_model = copy.deepcopy(model)\n","\n","  for epoch_i in range(epoch_n):\n","    try:\n","      epoch_start = datetime.datetime.now()\n","      print('Эпоха {}'.format(epoch_i))\n","\n","      model.train()\n","      mean_train_loss = 0\n","      train_batches_n = 0\n","      for batch_i, (batch_x, batch_y) in enumerate(train_dataloader):\n","        if batch_i > max_batches_per_epoch_train:\n","          break\n","\n","        batch_x = copy_data_to_device(batch_x, device)\n","        batch_y = copy_data_to_device(batch_y, device)\n","\n","        pred = model(batch_x)\n","        loss = criterion(pred, batch_y)\n","\n","        model.zero_grad()\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        mean_train_loss += float(loss)\n","        train_batches_n += 1\n","\n","      mean_train_loss /= train_batches_n\n","      print('Эпоха: {} итераций, {:0.2f} сек'.format(train_batches_n,\n","                                                     (datetime.datetime.now() - epoch_start).total_seconds()))\n","      print('Среднее значение функции потерь на обучении', mean_train_loss)\n","\n","      model.eval()\n","      mean_val_loss = 0\n","      val_batches_n = 0\n","\n","      with torch.no_grad():\n","        for batch_i, (batch_x, batch_y) in enumerate(val_dataloader):\n","          if batch_i > max_batches_per_epoch_val:\n","            break\n","\n","          batch_x = copy_data_to_device(batch_x, device)\n","          batch_y = copy_data_to_device(batch_y, device)\n","\n","          pred = model(batch_x)\n","          loss = criterion(pred, batch_y)\n","\n","          mean_val_loss += float(loss)\n","          val_batches_n += 1\n","\n","      mean_val_loss /= val_batches_n\n","      print('Среднее значение функции потерь на валидации', mean_val_loss)\n","\n","      if mean_val_loss < best_val_loss:\n","        best_epoch_i = epoch_i\n","        best_val_loss = mean_val_loss\n","        best_model = copy.deepcopy(model)\n","        print('Новая лучшая модель!')\n","      elif epoch_i - best_epoch_i > early_stopping_patience:\n","        print('Модель не улучшилась за за последние {} эпох, прекращаем обучение'.format(\n","            early_stopping_patience))\n","        break\n","\n","      if lr_scheduler is not None:\n","        lr_scheduler.step(mean_val_loss)\n","\n","      print()\n","    except KeyboardInterrupt:\n","      print('Досрочно остановлено пользователем')\n","      break\n","    except Exception as ex:\n","      print('Ошибка при обучении: {}\\n{}'.format(ex, traceback.format_exc()))\n","      break\n","\n","  return best_val_loss, best_model"],"metadata":{"id":"wNQaC4IDEJbm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["(best_val_loss,\n"," best_single_token_model) = train_eval_loop(single_token_model,\n","                                            train_dataset,\n","                                            test_dataset,\n","                                            F.cross_entropy,\n","                                            lr=5e-3,\n","                                            epoch_n=10,\n","                                            batch_size=64,\n","                                            device='cuda',\n","                                            early_stopping_patience=5,\n","                                            max_batches_per_epoch_train=500,\n","                                            max_batches_per_epoch_val=100,\n","                                            lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n","                                                                                                                       factor=0.5,\n","                                                                                                                       verbose=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3x72QRx1EB1k","executionInfo":{"status":"ok","timestamp":1644355594744,"user_tz":-300,"elapsed":166119,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"78da3d2e-96b8-4ee0-bead-d129945f25f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Эпоха 0\n","Досрочно остановлено пользователем\n"]}]},{"cell_type":"code","source":["torch.save(best_single_token_model.state_dict(), 'single_token_pos.pth')"],"metadata":{"id":"-U6rS6L_FsDK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["single_token_model.load_state_dict(torch.load('single_token_pos.pth'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YY5pn9AkJInq","executionInfo":{"status":"ok","timestamp":1644365584901,"user_tz":-300,"elapsed":9398,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"415006c1-fe8e-4ba6-bfb7-bbe86cf9e635"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","\n","def predict_with_model(model, dataset, device=None, batch_size=32, num_workers=0, return_labels=False):\n","  \"\"\"\n","  :param model: torch.nn.Module - обученная модель\n","  :param dataset: torch.utils.data.Dataset - данные для применения модели\n","  :param device: cuda/cpu - устройство, на котором выполнять вычисления\n","  :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n","  :return: numpy.array размерности len(dataset) x *\n","  \"\"\"\n","  if device is None:\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","  results_by_batch = []\n","\n","  device = torch.device(device)\n","  model.to(device)\n","  model.eval()\n","\n","  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","  labels = []\n","  with torch.no_grad():\n","    import tqdm\n","    for batch_x, batch_y in tqdm.tqdm(dataloader, total=len(dataset)/batch_size):\n","      batch_x = copy_data_to_device(batch_x, device)\n","\n","      if return_labels:\n","        labels.append(batch_y.numpy())\n","\n","      batch_pred = model(batch_x)\n","      results_by_batch.append(batch_pred.detach().cpu().numpy())\n","\n","  if return_labels:\n","    return np.concatenate(results_by_batch, 0), np.concatenate(labels, 0)\n","  else:\n","    return np.concatenate(results_by_batch, 0)"],"metadata":{"id":"1Aeyr1P6JcS2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_pred = predict_with_model(single_token_model, train_dataset)\n","train_loss = F.cross_entropy(torch.tensor(train_pred),\n","                             torch.tensor(train_labels))\n","print('Среднее значение функции потерь на обучении', float(train_loss))\n","print(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\n","print()\n","\n","test_pred = predict_with_model(single_token_model, test_dataset)\n","test_loss = F.cross_entropy(torch.tensor(test_pred),\n","                            torch.tensor(test_labels))\n","print('Среднее значение функции потерь на валидации', float(test_loss))\n","print(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mwA_LLrUJWHr","outputId":"f42fcfbe-4d32-4e66-cae0-39818cee4715"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["1526it [02:18, 11.03it/s]                               \n"]}]},{"cell_type":"markdown","source":["##Предсказание частей речи на уровне предложений (с учетом контекста)"],"metadata":{"id":"lnOnaelrvVhx"}},{"cell_type":"code","source":["class SentenceLevelPOSTagger(nn.Module):\n","  def __init__(self, vocab_size, labels_num, embedding_size=32, single_backbone_kwargs={}, context_backbone_kwargs={}):\n","    super().__init__()\n","    self.embedding_size = embedding_size\n","    self.char_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n","    self.single_token_backbone = StackedConv1d(embedding_size, **single_backbone_kwargs)\n","    self.context_backbone = StackedConv1d(embedding_size, **context_backbone_kwargs)\n","    self.global_pooling = nn.AdaptiveMaxPool1d(1)\n","    self.out = nn.Conv1d(embedding_size, labels_num, 1)\n","    self.labels_num = labels_num\n","\n","  def forward(self, tokens):\n","    \"\"\"tokens - BatchSize x MaxSentenceLen x MaxTokenLen\"\"\"\n","    batch_size, max_sent_len, max_token_len = tokens.shape\n","    tokens_flat = tokens.view(batch_size * max_sent_len, max_token_len)\n","\n","    char_embeddings = self.char_embeddings(tokens_flat)  # BatchSize*MaxSentenceLen x MaxTokenLen x EmbSize\n","    char_embeddings = char_embeddings.permute(0, 2, 1)  # BatchSize*MaxSentenceLen x EmbSize x MaxTokenLen\n","    char_features = self.single_token_backbone(char_embeddings)\n","\n","    token_features_flat = self.global_pooling(char_features).squeeze(-1)  # BatchSize*MaxSentenceLen x EmbSize\n","\n","    token_features = token_features_flat.view(batch_size, max_sent_len, self.embedding_size)  # BatchSize x MaxSentenceLen x EmbSize\n","    token_features = token_features.permute(0, 2, 1)  # BatchSize x EmbSize x MaxSentenceLen\n","    context_features = self.context_backbone(token_features)  # BatchSize x EmbSize x MaxSentenceLen\n","\n","    logits = self.out(context_features)  # BatchSize x LabelsNum x MaxSentenceLen\n","    return logits"],"metadata":{"id":"jVyCwkOnKzeJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentence_level_model = SentenceLevelPOSTagger(len(char_vocab), len(label2id), embedding_size=64,\n","                                              single_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3),\n","                                              context_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3))\n","print('Количество параметров', sum(np.product(t.shape) for t in sentence_level_model.parameters()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1_38hGW0TQ6","executionInfo":{"status":"ok","timestamp":1644365840260,"user_tz":-300,"elapsed":233,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"48f2855a-2db0-4074-d356-21d1f0279611"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Количество параметров 84882\n"]}]},{"cell_type":"code","source":["(best_val_loss,\n"," best_sentence_level_model) = train_eval_loop(sentence_level_model,\n","                                              train_dataset,\n","                                              test_dataset,\n","                                              F.cross_entropy,\n","                                              lr=5e-3,\n","                                              epoch_n=10,\n","                                              batch_size=64,\n","                                              device='cuda',\n","                                              early_stopping_patience=5,\n","                                              max_batches_per_epoch_train=500,\n","                                              max_batches_per_epoch_val=100,\n","                                              lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n","                                                                                                                         factor=0.5,\n","                                                                                                                         verbose=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AcJys2G-13xF","executionInfo":{"status":"ok","timestamp":1644370447081,"user_tz":-300,"elapsed":4449465,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"3aa44249-c319-4677-8a5d-7caa5c07b2d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Эпоха 0\n","Эпоха: 501 итераций, 617.63 сек\n","Среднее значение функции потерь на обучении 28.594766746738\n","Среднее значение функции потерь на валидации 45.03266615914826\n","Новая лучшая модель!\n","\n","Эпоха 1\n","Эпоха: 501 итераций, 617.19 сек\n","Среднее значение функции потерь на обучении 3925.2434413095198\n","Среднее значение функции потерь на валидации 2911.6879774036975\n","\n","Эпоха 2\n","Эпоха: 501 итераций, 617.21 сек\n","Среднее значение функции потерь на обучении 20447.585280367\n","Среднее значение функции потерь на валидации 135069.1051206683\n","\n","Эпоха 3\n","Эпоха: 501 итераций, 617.51 сек\n","Среднее значение функции потерь на обучении 410083.71241891215\n","Среднее значение функции потерь на валидации 799348.7892945545\n","Epoch     4: reducing learning rate of group 0 to 2.5000e-03.\n","\n","Эпоха 4\n","Эпоха: 501 итераций, 617.47 сек\n","Среднее значение функции потерь на обучении 399584.1848490519\n","Среднее значение функции потерь на валидации 204326.24450804456\n","\n","Эпоха 5\n","Эпоха: 501 итераций, 617.49 сек\n","Среднее значение функции потерь на обучении 505669.4923278443\n","Среднее значение функции потерь на валидации 323094.23143564357\n","\n","Эпоха 6\n","Эпоха: 501 итераций, 617.43 сек\n","Среднее значение функции потерь на обучении 868946.6439620758\n","Среднее значение функции потерь на валидации 358958.21967821784\n","Модель не улучшилась за за последние 5 эпох, прекращаем обучение\n"]}]},{"cell_type":"code","source":["torch.save(best_sentence_level_model.state_dict(), 'sentence_level_pos.pth')"],"metadata":{"id":"AcyH26_K2eNm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentence_level_model.load_state_dict(torch.load('sentence_level_pos.pth'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0WpyDBmJWJy","executionInfo":{"status":"ok","timestamp":1644370997159,"user_tz":-300,"elapsed":232,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"58bd06c9-8aa2-4988-a342-3172d2136d59"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["train_pred = predict_with_model(sentence_level_model, train_dataset)\n","train_loss = F.cross_entropy(torch.tensor(train_pred),\n","                             torch.tensor(train_labels))\n","print('Среднее значение функции потерь на обучении', float(train_loss))\n","print(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\n","print()\n","\n","test_pred = predict_with_model(sentence_level_model, test_dataset)\n","test_loss = F.cross_entropy(torch.tensor(test_pred),\n","                            torch.tensor(test_labels))\n","print('Среднее значение функции потерь на валидации', float(test_loss))\n","print(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MngyBNm-Jixx","executionInfo":{"status":"ok","timestamp":1644371153141,"user_tz":-300,"elapsed":21577,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"d59a197f-e170-4c3e-9fcb-5ddcd65f17fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 206/205.75 [00:19<00:00, 10.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Среднее значение функции потерь на валидации 44.708984375\n","              precision    recall  f1-score   support\n","\n","     <NOTAG>       1.00      1.00      1.00   1231232\n","         ADJ       0.00      0.00      0.00     11222\n","         ADP       0.73      0.49      0.59     10585\n","         ADV       0.00      0.00      0.00      6165\n","         AUX       0.33      0.04      0.07      1106\n","       CCONJ       0.00      0.00      0.00      4410\n","         DET       0.02      0.01      0.02      3085\n","        INTJ       0.00      0.00      0.00        11\n","        NOUN       0.31      0.95      0.47     27974\n","         NUM       0.00      0.00      0.00      1829\n","        PART       0.00      0.00      0.00      3877\n","        PRON       0.00      0.00      0.00      5598\n","       PROPN       0.00      0.00      0.00      4438\n","       PUNCT       0.94      0.96      0.95     22694\n","       SCONJ       0.00      0.00      0.00      2258\n","         SYM       0.00      0.00      0.00        53\n","        VERB       0.00      0.00      0.00     13078\n","           X       0.00      0.00      0.00       105\n","\n","    accuracy                           0.95   1349720\n","   macro avg       0.18      0.19      0.17   1349720\n","weighted avg       0.94      0.95      0.94   1349720\n","\n"]}]},{"cell_type":"markdown","source":["##Применение полученных теггеров и сравнение"],"metadata":{"id":"FUk88o3CKRly"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import TensorDataset\n","\n","class POSTagger:\n","  def __init__(self, model, char2id, id2label, max_sent_len, max_token_len):\n","    self.model = model\n","    self.char2id = char2id\n","    self.id2label = id2label\n","    self.max_sent_len = max_sent_len\n","    self.max_token_len = max_token_len\n","\n","  def __call__(self, sentences):\n","    tokenized_corpus = tokenize_corpus(sentences, min_token_size=1)\n","\n","    inputs = torch.zeros((len(sentences), self.max_sent_len, self.max_token_len + 2), dtype=torch.long)\n","\n","    for sent_i, sentence in enumerate(tokenized_corpus):\n","      for token_i, token in enumerate(sentence):\n","        for char_i, char in enumerate(token):\n","          inputs[sent_i, token_i, char_i + 1] = self.char2id.get(char, 0)\n","\n","    dataset = TensorDataset(inputs, torch.zeros(len(sentences)))\n","    predicted_probs = predict_with_model(self.model, dataset)  # SentenceN x TagsN x MaxSentLen\n","    predicted_classes = predicted_probs.argmax(1)\n","\n","    result = []\n","    for sent_i, sent in enumerate(tokenized_corpus):\n","      result.append([self.id2label[cls] for cls in predicted_classes[sent_i, :len(sent)]])\n","    return result"],"metadata":{"id":"iOn8ZgWFKDpa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["single_token_pos_tagger = POSTagger(single_token_model, char_vocab, UNIQUE_TAGS, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)\n","sentence_level_pos_tagger = POSTagger(sentence_level_model, char_vocab, UNIQUE_TAGS, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)"],"metadata":{"id":"CXsztKDqNhL6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_sentences = ['Мама мыла раму.',\n","                  'Косил косой косой косой.',\n","                  'Глокая куздра штеко будланула бокра и куздрячит бокрёнка.',\n","                  'Сяпала Калуша с Калушатами по напушке.',\n","                  'Пирожки поставлены в печь, мама любит печь.',\n","                  'Ведро дало течь, вода стала течь.',\n","                  'Три да три, будет дырка.',\n","                  'Три да три, будет шесть.',\n","                  'Сорок сорок']\n","test_sentences_tokenized = tokenize_corpus(test_sentences, min_token_size=1)"],"metadata":{"id":"cSUMHNOpOAWj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for sent_tokens, sent_tags in zip(test_sentences_tokenized, single_token_pos_tagger(test_sentences)):\n","  print(' '.join('{}-{}'.format(tok, tag) for tok, tag in zip(sent_tokens, sent_tags)))\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wYYTRKQwOdWd","executionInfo":{"status":"ok","timestamp":1644372406028,"user_tz":-300,"elapsed":235,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"b0cb5527-17e2-4bfb-992a-b929c376e5a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["1it [00:00, 17.04it/s]                     "]},{"output_type":"stream","name":"stdout","text":["мама-NOUN мыла-ADP раму-NOUN\n","\n","косил-NOUN косой-NOUN косой-NOUN косой-NOUN\n","\n","глокая-NOUN куздра-NOUN штеко-NOUN будланула-NOUN бокра-NOUN и-NOUN куздрячит-NOUN бокрёнка-NOUN\n","\n","сяпала-NOUN калуша-NOUN с-NOUN калушатами-NOUN по-NOUN напушке-NOUN\n","\n","пирожки-NOUN поставлены-NOUN в-NOUN печь-NOUN мама-NOUN любит-NOUN печь-NOUN\n","\n","ведро-NOUN дало-NOUN течь-NOUN вода-NOUN стала-NOUN течь-NOUN\n","\n","три-NOUN да-NOUN три-NOUN будет-NOUN дырка-NOUN\n","\n","три-NOUN да-NOUN три-NOUN будет-NOUN шесть-NOUN\n","\n","сорок-NOUN сорок-NOUN\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["for sent_tokens, sent_tags in zip(test_sentences_tokenized, sentence_level_pos_tagger(test_sentences)):\n","  print(' '.join('{}-{}'.format(tok, tag) for tok, tag in zip(sent_tokens, sent_tags)))\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q0psq-UFO6tp","executionInfo":{"status":"ok","timestamp":1644372462726,"user_tz":-300,"elapsed":320,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"0c026645-a40f-47f4-cbb3-9f66ad9ed4d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["1it [00:00, 24.95it/s]                     "]},{"output_type":"stream","name":"stdout","text":["мама-NOUN мыла-NOUN раму-NOUN\n","\n","косил-NOUN косой-NOUN косой-NOUN косой-NOUN\n","\n","глокая-NOUN куздра-NOUN штеко-NOUN будланула-NOUN бокра-NOUN и-NOUN куздрячит-NOUN бокрёнка-NOUN\n","\n","сяпала-NOUN калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN\n","\n","пирожки-NOUN поставлены-NOUN в-ADP печь-NOUN мама-NOUN любит-NOUN печь-NOUN\n","\n","ведро-NOUN дало-NOUN течь-NOUN вода-NOUN стала-NOUN течь-NOUN\n","\n","три-DET да-NOUN три-NOUN будет-NOUN дырка-NOUN\n","\n","три-DET да-NOUN три-NOUN будет-NOUN шесть-NOUN\n","\n","сорок-NOUN сорок-NOUN\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["##Сверточный модуль своими руками"],"metadata":{"id":"jPogZveuPONf"}},{"cell_type":"code","source":["class MyConv1d(nn.Module):\n","  def __init__(self, in_channels, out_channels, kernel_size, padding=0):\n","    super().__init__()\n","    self.in_channels = in_channels\n","    self.out_channels = out_channels\n","    self.kernel_size = kernel_size\n","    self.padding = padding\n","    self.weight = nn.Parameter(torch.randn(in_channels * kernel_size, out_channels) / (in_channels * kernel_size),\n","                               requires_grad=True)\n","    self.bias = nn.Parameter(torch.zeros(out_channels), requires_grad=True)\n","\n","  def forward(self, x):\n","    \"\"\"x - BatchSize x InChannels x SequenceLen\"\"\"\n","\n","    batch_size, src_channels, sequence_len = x.shape\n","    if self.padding > 0:\n","      pad = x.new_zeros(batch_size, src_channels, self.padding)\n","      x = torch.cat((pad, x, pad), dim=-1)\n","      sequence_len = x.shape[-1]\n","\n","    chunks = []\n","    chunk_size = sequence_len - self.kernel_size + 1\n","    for offset in range(self.kernel_size):\n","      chunks.append(x[:, :, offset:offset + chunk_size])\n","\n","    in_features = torch.cat(chunks, dim=1)  # BatchSize x InChannels * KernelSize x ChunkSize\n","    in_features = in_features.permute(0, 2, 1)  # BatchSize x ChunkSize x InChannels * KernelSize\n","    out_features = torch.bmm(in_features, self.weight.unsqueeze(0).expand(batch_size, -1, -1)) + self.bias.unsqueeze(0).unsqueeze(0)\n","    out_features = out_features.permute(0, 2, 1)  # BatchSize x OutChannels x ChunkSize\n","    return out_features"],"metadata":{"id":"XrUq4V0HPIkW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentence_level_model_my_conv = SentenceLevelPOSTagger(len(char_vocab), len(label2id), embedding_size=64,\n","                                                      single_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3, conv_layer=MyConv1d),\n","                                                      context_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3, conv_layer=MyConv1d))\n","print('Количество параметров', sum(np.product(t.shape) for t in sentence_level_model_my_conv.parameters()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1QXPBJ-5UXhm","executionInfo":{"status":"ok","timestamp":1644374138048,"user_tz":-300,"elapsed":255,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"307950a7-46f1-4d96-b6f3-77dfb0daa01f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Количество параметров 84882\n"]}]},{"cell_type":"code","source":["(best_val_loss,\n"," best_sentence_level_model_my_conv) = train_eval_loop(sentence_level_model_my_conv,\n","                                                      train_dataset,\n","                                                      test_dataset,\n","                                                      F.cross_entropy,\n","                                                      lr=5e-3,\n","                                                      epoch_n=10,\n","                                                      batch_size=64,\n","                                                      device='cuda',\n","                                                      early_stopping_patience=5,\n","                                                      max_batches_per_epoch_train=500,\n","                                                      max_batches_per_epoch_val=100,\n","                                                      lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n","                                                                                                                                 factor=0.5,\n","                                                                                                                                 verbose=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oMrnEPKZVhki","executionInfo":{"status":"ok","timestamp":1644377093111,"user_tz":-300,"elapsed":2461096,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"1f66c82c-bd47-451a-d13f-6d7486f1369e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Эпоха 0\n","Эпоха: 501 итераций, 326.71 сек\n","Среднее значение функции потерь на обучении 84483.94761609969\n","Среднее значение функции потерь на валидации 163358.02978032178\n","Новая лучшая модель!\n","\n","Эпоха 1\n","Эпоха: 501 итераций, 326.64 сек\n","Среднее значение функции потерь на обучении 509476.910491517\n","Среднее значение функции потерь на валидации 531235.9186262377\n","\n","Эпоха 2\n","Эпоха: 501 итераций, 326.63 сек\n","Среднее значение функции потерь на обучении 816864.9846556886\n","Среднее значение функции потерь на валидации 366979.08570544556\n","\n","Эпоха 3\n","Эпоха: 501 итераций, 326.52 сек\n","Среднее значение функции потерь на обучении 1744346.4209081836\n","Среднее значение функции потерь на валидации 1512973.7747524753\n","Epoch     4: reducing learning rate of group 0 to 2.5000e-03.\n","\n","Эпоха 4\n","Эпоха: 501 итераций, 326.43 сек\n","Среднее значение функции потерь на обучении 1168953.1333582834\n","Среднее значение функции потерь на валидации 435234.8917079208\n","\n","Эпоха 5\n","Эпоха: 501 итераций, 326.60 сек\n","Среднее значение функции потерь на обучении 1068057.0780938123\n","Среднее значение функции потерь на валидации 827329.041769802\n","\n","Эпоха 6\n","Эпоха: 501 итераций, 326.48 сек\n","Среднее значение функции потерь на обучении 1396380.791541916\n","Среднее значение функции потерь на валидации 863736.2224628713\n","Модель не улучшилась за за последние 5 эпох, прекращаем обучение\n"]}]},{"cell_type":"code","source":["torch.save(best_sentence_level_model_my_conv.state_dict(), 'sentence_level_pos_my_conv.pth')"],"metadata":{"id":"ugTuREPfW2Hg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_sentence_level_model_my_conv.load_state_dict(torch.load('sentence_level_pos_my_conv.pth'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uDf2B1sqW3Eh","executionInfo":{"status":"ok","timestamp":1644377198605,"user_tz":-300,"elapsed":245,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"385ddbd0-4ef2-4954-8b80-2ba385c155eb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["train_pred = predict_with_model(best_sentence_level_model_my_conv, train_dataset)\n","train_loss = F.cross_entropy(torch.tensor(train_pred),\n","                             torch.tensor(train_labels))\n","print('Среднее значение функции потерь на обучении', float(train_loss))\n","print(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\n","print()\n","\n","test_pred = predict_with_model(best_sentence_level_model_my_conv, test_dataset)\n","test_loss = F.cross_entropy(torch.tensor(test_pred),\n","                            torch.tensor(test_labels))\n","print('Среднее значение функции потерь на валидации', float(test_loss))\n","print(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cB5gquLuWKrg","executionInfo":{"status":"ok","timestamp":1644377285081,"user_tz":-300,"elapsed":27339,"user":{"displayName":"Михаил Мокроносов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15504315815603897107"}},"outputId":"3260bdad-801b-4ced-ef6e-d5f68460859c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 206/205.75 [00:24<00:00,  8.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Среднее значение функции потерь на валидации 161955.765625\n","              precision    recall  f1-score   support\n","\n","     <NOTAG>       0.99      0.02      0.03   1231232\n","         ADJ       0.03      0.00      0.00     11222\n","         ADP       0.16      0.01      0.02     10585\n","         ADV       0.00      0.00      0.00      6165\n","         AUX       0.00      0.00      0.00      1106\n","       CCONJ       0.00      0.00      0.00      4410\n","         DET       0.04      0.11      0.06      3085\n","        INTJ       0.00      0.00      0.00        11\n","        NOUN       0.02      0.70      0.03     27974\n","         NUM       0.00      0.00      0.00      1829\n","        PART       0.00      0.00      0.00      3877\n","        PRON       0.00      0.00      0.00      5598\n","       PROPN       0.20      0.00      0.00      4438\n","       PUNCT       0.50      0.97      0.66     22694\n","       SCONJ       0.09      0.01      0.03      2258\n","         SYM       0.00      0.00      0.00        53\n","        VERB       0.36      0.10      0.16     13078\n","           X       0.00      0.00      0.00       105\n","\n","    accuracy                           0.05   1349720\n","   macro avg       0.13      0.11      0.06   1349720\n","weighted avg       0.91      0.05      0.04   1349720\n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"orzDtX-xhbTS"},"execution_count":null,"outputs":[]}]}